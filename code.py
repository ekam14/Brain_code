# -*- coding: utf-8 -*-
"""v1.5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wvloY1UgbT3XtN1HV-AT2auHXom436De

# Brain Segmentation Project
"""

from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir("/content/drive/My Drive/")

!ls

i=0
print(f'{i}')

"""# Importing Libraries"""



import keras
from keras.preprocessing.image import img_to_array
from keras import layers,models
from keras.layers import Maximum,Conv2D,BatchNormalization,Dropout,Concatenate,Input,Activation
from keras.models import Model
import numpy as np
import keras.backend as K

"""# Evaluation Metrics"""

def precision(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision


def recall(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def sensitivity(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def dice(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    dice = (true_positives*2) /(possible_positives + K.epsilon() + true_positives)
    return dice

def fbeta_score(y_true, y_pred, beta=1):
    if beta < 0:
        raise ValueError('The lowest choosable beta is zero (only precision).')
        
    # If there are no true positives, fix the F score at 0 like sklearn.
    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:
        return 0

    p = precision(y_true, y_pred)
    r = recall(y_true, y_pred)
    bb = beta ** 2
    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())
    return fbeta_score


def fmeasure(y_true, y_pred):
    return fbeta_score(y_true, y_pred, beta=1)

def get(identifier):
    return get_from_module(identifier, globals(), 'metric')

"""# Model Architectures

# Base Model: Two Path Model (Global + Local Path)
"""

def two_path(x_input):
  
    x = Conv2D(64,(7,7),strides=(1,1),padding='valid')(x_input)
    x = BatchNormalization()(x)
    x1 = Conv2D(64,(7,7),strides=(1,1),padding='valid')(x_input)
    x1 = BatchNormalization()(x1)
    x = layers.Maximum()([x,x1])
    x = Conv2D(64,(4,4),strides=(1,1),padding='valid',activation='relu')(x)

    x2 = Conv2D(160,(13,13),strides=(1,1),padding='valid')(x_input)
    x2 = BatchNormalization()(x2)
    x21 = Conv2D(160,(13,13),strides=(1,1),padding='valid')(x_input)
    x21 = BatchNormalization()(x21)
    x2 = layers.Maximum()([x2,x21])

    x3 = Conv2D(64,(3,3),strides=(1,1),padding='valid')(x)
    x3 = BatchNormalization()(x3)
    x31 =  Conv2D(64,(3,3),strides=(1,1),padding='valid')(x)
    x31 = BatchNormalization()(x31)
    x = layers.Maximum()([x3,x31])
    x = Conv2D(64,(2,2),strides=(1,1),padding='valid',activation='relu')(x)

    x = Concatenate()([x2,x])
    return x

"""# Cascade_1: Input Cascade"""

def input_cascade(input_shape1,input_shape2):
  
    x1_input = Input(input_shape1)
    x1 = two_path(x1_input)
    x1 = Conv2D(5,(21,21),strides=(1,1),padding='valid',activation='relu')(x1)
    x1 = BatchNormalization()(x1)

    x2_input = Input(input_shape2)
    x2_input1 = Concatenate()([x1,x2_input])
    x2 = two_path(x2_input1)
    x2 = Conv2D(5,(21,21),strides=(1,1),padding='valid')(x2)
    x2 = BatchNormalization()(x2)
    x2 = Activation('softmax')(x2)

    model = Model(inputs=[x1_input,x2_input],outputs=x2)
    return model

"""# Model Summary and Compilation"""

m_input_cascade = input_cascade((65,65,4),(33,33,4))
m_input_cascade.summary()
m_input_cascade.compile(optimizer='adam',loss='categorical_crossentropy',metrics=[dice,precision,sensitivity])

"""# Cascade_2: MFC Cascade"""

def MFCcascade(input_shape1,input_shape2):
  
    x1_input = Input(input_shape1)
    x1 = two_path(x1_input)
    x1 = Conv2D(5,(21,21),strides=(1,1),padding='valid',activation='relu')(x1)
    x1 = BatchNormalization()(x1)
    #x1 = MaxPooling2D((2,2))(x1)

    x2_input = Input(input_shape2)
    x2 = two_path(x2_input)

    x2 = Concatenate()([x1,x2])
    x2 = Conv2D(5,(21,21),strides=(1,1),padding='valid',activation='relu')(x2)
    x2 = BatchNormalization()(x2)
    x2 = Activation('softmax')(x2)

    model = Model(inputs=[x1_input,x2_input],outputs=x2)
    return model

"""# Model Summary and Compilation"""

m_MFCcascade = MFCcascade((53,53,4),(33,33,4))
m_MFCcascade.summary()
m_MFCcascade.compile(optimizer='adam',loss='categorical_crossentropy',metrics=[dice,precision,sensitivity])

import matplotlib.pyplot as plt
def my_plot(h):  
    dice1 = h['dice']
    precision1=h['precision']
    sensitivity1=h['sensitivity']
    loss = h['loss']
    epochs = range(1,len(dice1)+1)

    plt.plot(epochs,dice1,'r',label='Dice Score')
    plt.plot(epochs,precision1,'b',label='Precision Score')
    plt.plot(epochs,sensitivity1,'g',label='Sensitivity Score')
    plt.title('Training Observations')
    plt.legend()

    plt.figure()
    plt.plot(epochs,loss,'r',label='Loss')
    plt.title('Training Loss')
    plt.legend()
    
    plt.show()

!pip install SimpleITK
import SimpleITK as sitk
import os
init = ''

"""# Operational Function for Different Models"""

def data_gen(data,y,slice_no,model_no):
  d = []
  x = data[slice_no]
  #filtering all 0 slices and non-tumor slices
  if(x.any() != 0 and y.any() != 0):
    if(model_no == 0):
      X1 = []
      for i in range(16,159):
        for j in range(16,199):
          if(x[i-16:i+17,j-16:j+17,:].all != 0):
            X1.append(x[i-16:i+17,j-16:j+17,:])
      Y1 = []
      for i in range(16,159):
        for j in range(16,199):
          if(x[i-16:i+17,j-16:j+17,:].all != 0):
            Y1.append(y[i,slice_no,j]) 
      X1 = np.asarray(X1)
      Y1 = np.asarray(Y1)
      d = [X1,Y1]
    elif(model_no == 1):
      d = model_gen(65,x,y,slice_no)
    elif(model_no == 2):
      d = model_gen(56,x,y,slice_no)
    elif(model_no == 3):
      d = model_gen(53,x,y,slice_no)  
    
  return d

def model_gen(input_dim,x,y,slice_no):
  X1 = []
  X2 = []
  Y = []
  
  for i in range(int((input_dim)/2),y.shape[0]-int((input_dim)/2)):
    for j in range(int((input_dim)/2),y.shape[2]-int((input_dim)/2)):
      #Filtering all 0 patches
      if(x[i-16:i+17,j-16:j+17,:].any != 0):
        X2.append(x[i-16:i+17,j-16:j+17,:])
        X1.append(x[i-int((input_dim)/2):i+int((input_dim)/2)+1,j-int((input_dim)/2):j+int((input_dim)/2)+1,:])
        Y.append(y[i,slice_no,j])
      
      
  X1 = np.asarray(X1)
  X2 = np.asarray(X2)
  Y = np.asarray(Y)
  d = [X1,X2,Y]
  return d

from sklearn.utils import class_weight

"""# First Training Round (Train for Balanced data)

# Input Cascade

# Split of Train Images and Labels
"""

m_input_cascade.load_weights('trial_12543_input_cascasde_acc.h5')

import time
j=100

now = time.time()

fold = os.listdir(init+'HG/')
fold.sort(key=str.lower) 

for path in fold:
    path = init+'HG/'+path
    p = os.listdir(path)
    p.sort(key=str.lower)
    arr = []
    
    # Reading from 4 images and creating 4 channel slice-wise 
    for i in range(len(p)):
      if(i != 4):
        p1 = os.listdir(path+'/'+p[i])
        p1.sort()
        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[-1])
        arr.append(sitk.GetArrayFromImage(img))
      else:
        p1 = os.listdir(path+'/'+p[i])
        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[0])
        Y_labels = sitk.GetArrayFromImage(img)
    data = np.zeros((Y_labels.shape[1],Y_labels.shape[0],Y_labels.shape[2],4))
    for i in range(Y_labels.shape[1]):
      data[i,:,:,0] = arr[0][:,i,:]
      data[i,:,:,1] = arr[1][:,i,:]
      data[i,:,:,2] = arr[2][:,i,:]
      data[i,:,:,3] = arr[3][:,i,:]
    info = []
    
    # Creating patches for each slice and training(slice-wise)
    for i in range(data.shape[0]):
      d = data_gen(data,Y_labels,i,1)
      if(len(d) != 0):
        y = np.zeros((d[2].shape[0],1,1,5))
        for j in range(y.shape[0]):
          y[j,:,:,int(d[2][j])] = 1
        X1 = d[0]
        X2 = d[1]
        class_weights = class_weight.compute_class_weight('balanced',
                                                          np.unique(d[2]),
                                                          d[2])
        print('slice no:'+str(i))
        history = m_input_cascade.fit([X1,X2],y,epochs=2,batch_size=128,class_weight= class_weights)
        info.append(history)
    m_input_cascade.save(f'trial_{j}_input_cascasde_acc.h5')
    j = j+1
        
print(time.time()-now)

!ls "/content/drive/My Drive/"

"""# Ploting based on Evaluation metrics"""

from google.colab import files
with open(f"history2",'w+') as file:
  for (i,x) in enumerate(info):
    file.write(str(info[i].history))

"""# MFC Cascade"""

fold = os.listdir(init+'HG/')
fold.sort(key=str.lower) 

for path in ['0001','0002','0003']:
    print(path)
    path = init+'HG/'+path
    p = os.listdir(path)
    p.sort(key=str.lower)
    arr = []
    
    # Reading from 4 images and creating 4 channel slice-wise 
    for i in range(len(p)):
      if(i != 4):
        p1 = os.listdir(path+'/'+p[i])
        p1.sort()
        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[-1])
        arr.append(sitk.GetArrayFromImage(img))
      else:
        p1 = os.listdir(path+'/'+p[i])
        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[0])
        Y_labels = sitk.GetArrayFromImage(img)
        print(np.array(Y_labels).shape)
    data = np.zeros((Y_labels.shape[1],Y_labels.shape[0],Y_labels.shape[2],4))
    for i in range(Y_labels.shape[1]):
      data[i,:,:,0] = arr[0][:,i,:]
      data[i,:,:,1] = arr[1][:,i,:]
      data[i,:,:,2] = arr[2][:,i,:]
      data[i,:,:,3] = arr[3][:,i,:]
    print(data.shape)
    info_MFCcascade_1T = []
    
    # Creating patches for each slice and training(slice-wise)
    for i in range(data.shape[0]):
      d = data_gen(data,Y_labels,i,3)
      
      if(len(d) != 0):
        print(d[2].shape)
        y = np.zeros((d[2].shape[0],1,1,5))
        for j in range(y.shape[0]):
          y[j,:,:,int(d[2][j])] = 1
        X1 = d[0]
        X2 = d[1]
        class_weights = class_weight.compute_class_weight('balanced',
                                                          np.unique(d[2]),
                                                          d[2])
        print('slice no:'+str(i))
        
        
        
        info_MFCcascade_1T.append(m_MFCcascade.fit([X1,X2],y,epochs=3,batch_size=16,class_weight= class_weights))
    
        m_MFCcascade.save('Model_MFCcascade_1st_Training_001.h5')

"""# Ploting based on Evaluation metrics"""

my_plot(info_MFCcascade_1T[-1].history)

"""# Second Training Round (Make only Last Layer Trainible for Unbalanced data)

# Input Cascade
"""

fold = os.listdir(init+'HG/')
fold.sort(key=str.lower) 

for path in ['0001','0002','0003']:
    print(path)
    path = init+'HG/'+path
    p = os.listdir(path)
    p.sort(key=str.lower)
    arr = []
    
    # Reading from 4 images and creating 4 channel slice-wise 
    for i in range(len(p)):
      if(i != 4):
        p1 = os.listdir(path+'/'+p[i])
        p1.sort()
        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[-1])
        arr.append(sitk.GetArrayFromImage(img))
      else:
        p1 = os.listdir(path+'/'+p[i])
        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[0])
        Y_labels = sitk.GetArrayFromImage(img)
        print(np.array(Y_labels).shape)
    data = np.zeros((Y_labels.shape[1],Y_labels.shape[0],Y_labels.shape[2],4))
    for i in range(Y_labels.shape[1]):
      data[i,:,:,0] = arr[0][:,i,:]
      data[i,:,:,1] = arr[1][:,i,:]
      data[i,:,:,2] = arr[2][:,i,:]
      data[i,:,:,3] = arr[3][:,i,:]
    print(data.shape)
    info_input_cascade_2T = []
    
    # Creating patches for each slice and training(slice-wise)
    for i in range(data.shape[0]):
      d = data_gen(data,Y_labels,i,1)
      
      if(len(d) != 0):
        print(d[2].shape)
        y = np.zeros((d[2].shape[0],1,1,5))
        for j in range(y.shape[0]):
          y[j,:,:,int(d[2][j])] = 1
        X1 = d[0]
        X2 = d[1]
        class_weights = class_weight.compute_class_weight(None,
                                                          np.unique(d[2]),
                                                          d[2])
        print('slice no:'+str(i))
       
    
        #Make only Last Layer Trainible
        for layer in m_input_cascade.layers:
            layer.trainable = False

        for layer in m_input_cascade.layers[-1:]:
            layer.trainable = True
        
        info_input_cascade_2T.append(m_input_cascade.fit([X1,X2],y,epochs=3,batch_size=16,class_weight= class_weights))
    
        m_input_cascade.save('Model_input_cascade_2nd_Training__001.h5')

"""# Ploting based on Evaluation metrics"""

my_plot(info_input_cascade_2T[0].history)

"""# MFC Cascade"""

fold = os.listdir(init+'HG/')
fold.sort(key=str.lower) 

for path in ['0001','0002','0003']:
    print(path)
    path = init+'HG/'+path
    p = os.listdir(path)
    p.sort(key=str.lower)
    arr = []
    
    # Reading from 4 images and creating 4 channel slice-wise 
    for i in range(len(p)):
      if(i != 4):
        p1 = os.listdir(path+'/'+p[i])
        p1.sort()
        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[-1])
        arr.append(sitk.GetArrayFromImage(img))
      else:
        p1 = os.listdir(path+'/'+p[i])
        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[0])
        Y_labels = sitk.GetArrayFromImage(img)
        print(np.array(Y_labels).shape)
    data = np.zeros((Y_labels.shape[1],Y_labels.shape[0],Y_labels.shape[2],4))
    for i in range(Y_labels.shape[1]):
      data[i,:,:,0] = arr[0][:,i,:]
      data[i,:,:,1] = arr[1][:,i,:]
      data[i,:,:,2] = arr[2][:,i,:]
      data[i,:,:,3] = arr[3][:,i,:]
    print(data.shape)
    info_MFCcascade_2T = []
    
    # Creating patches for each slice and training(slice-wise)
    for i in range(data.shape[0]):
      d = data_gen(data,Y_labels,i,3)
      
      if(len(d) != 0):
        print(d[2].shape)
        y = np.zeros((d[2].shape[0],1,1,5))
        for j in range(y.shape[0]):
          y[j,:,:,int(d[2][j])] = 1
        X1 = d[0]
        X2 = d[1]
        class_weights = class_weight.compute_class_weight(None,
                                                          np.unique(d[2]),
                                                          d[2])
        print('slice no:'+str(i))
        
        for layer in m_MFCcascade.layers:
            layer.trainable = False

        for layer in m_MFCcascade.layers[-1:]:
            layer.trainable = True
            
            
        info_MFCcascade_2T.append(m_MFCcascade.fit([X1,X2],y,epochs=3,batch_size=16,class_weight= class_weights))
    
        m_MFCcascade.save('Model_MFCcascade_2nd_Training_001.h5')

"""# Ploting based on Evaluation metrics"""

my_plot(info_MFCcascade_2T[0].history)

"""# Testing

# Input Cascade
"""

from sklearn import metrics
m_input_cascade.load_weights('HG_input_cascasde(final_weights).h5')

import time
f1_p = []
p_p = []
recall_p = []
fold = os.listdir(init+'HG/')
fold.sort(key=str.lower) 

slices = [105,106,107,108,109,110,111,112,113]

for path in fold:
    print(path)
    path = init+'HG/'+path
    p = os.listdir(path)
    p.sort(key=str.lower)
    arr = []
    
    # Reading from 4 images and creating 4 channel slice-wise 
    for i in range(len(p)):
      if(i != 4):
        p1 = os.listdir(path+'/'+p[i])
        p1.sort()
        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[-1])
        arr.append(sitk.GetArrayFromImage(img))
      else:
        p1 = os.listdir(path+'/'+p[i])
        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[0])
        Y_labels = sitk.GetArrayFromImage(img)
        print(np.array(Y_labels).shape)
    data = np.zeros((Y_labels.shape[1],Y_labels.shape[0],Y_labels.shape[2],4))
    for i in range(Y_labels.shape[1]):
      data[i,:,:,0] = arr[0][:,i,:]
      data[i,:,:,1] = arr[1][:,i,:]
      data[i,:,:,2] = arr[2][:,i,:]
      data[i,:,:,3] = arr[3][:,i,:]
    
    # Creating patches for each slice and training(slice-wise)
    for i in slices:
      now = time.time()
      d = data_gen(data,Y_labels,i,1)
      
      if(len(d) != 0):
        y = np.zeros((d[2].shape[0],1,1,5))
        for j in range(y.shape[0]):
          y[j,:,:,int(d[2][j])] = 1
        X1 = d[0]
        X2 = d[1]
        pred = m_input_cascade.predict([X1,X2],batch_size = 16) 
        pred = np.around(pred)
        pred1 = np.argmax(pred.reshape(y.shape[0],5)[:,1:4],axis = 1)
        y2 = np.argmax(y.reshape(y.shape[0],5)[:,1:4],axis = 1)
        f1 = metrics.precision_recall_fscore_support(y2,pred1,average='micro')
        #pre = metrics.precision_score(y2,pred1,average='micro')
        #recall = metrics.recall_score(y2,pred1,average='micro')
        
        
        f1_p.append(f1)
        #recall_p.append(recall)
        #p_p.append(pre)
        
        print(f'slice no. {i}: {time.time()-now} seconds')

print(slices)
print(f1_p)
#print(np.average(p_p))
#print(np.average(recall_p))

print(f1_p)
print(recall_p)

f1 = metrics.f1_score(y2,pred1,average='micro')
print("Dice or F1 Score="+str(f1))
c1=metrics.confusion_matrix(y2,pred1)
print("confusion_matrix=")
print(c1)
sensitivity1=c1[0][0]/(c1[0][0]+c1[0][1])
print("Sensitivity= "+str(sensitivity1))
Specificity1=c1[1][1]/(c1[1][1]+c1[1][0])
print("Specificity= "+str(Specificity1))

"""# MFC Cascade"""

d1 = data_gen(data,Y_labels,113,3)
if(len(d1) != 0):
    y3 = np.zeros((d1[2].shape[0],1,1,5))
    for j in range(y3.shape[0]):
        y3[j,:,:,int(d1[2][j])] = 1
    X3 = d1[0]
    X4 = d1[1]
    pred3 = m_MFCcascade.predict([X3,X4],batch_size = 16) 
    pred3 = np.around(pred3)
    #print(pred3.shape)
    pred4 = np.argmax(pred3.reshape(y3.shape[0],5)[:,1:4],axis = 1)
    y4 = np.argmax(y3.reshape(y3.shape[0],5)[:,1:4],axis = 1)

f1_2 = metrics.f1_score(y4,pred4,average='micro')
print("Dice or F1 Score="+str(f1_2))
c2=metrics.confusion_matrix(y4,pred4)
print("confusion_matrix=")
print(c2)
sensitivity=c2[0][0]/(c2[0][0]+c2[0][1])
print("Sensitivity= "+str(sensitivity))
Specificity=c2[1][1]/(c2[1][1]+c2[1][0])
print("Specificity= "+str(Specificity))

